{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import CSVLogger\n",
    "from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7409746607558104790\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3157314764\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5694250095082357475\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "x_val = np.load(\"x_val.npy\")\n",
    "y_val = np.load(\"y_val.npy\")\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22046, 200, 200, 3) (22046, 2)\n",
      "(2756, 200, 200, 3) (2756, 200, 200, 3) (2756, 2) (2756, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, x_test.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 200\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "TEST_LOGS_FILE = \"test_logs.csv\"\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
    "TEST_FILE = \"test_file.txt\"\n",
    "MODEL_FILE = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(200, 200,..., activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 10,676,002\n",
      "Trainable params: 10,676,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32, 3, 3, border_mode='same', input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Conv2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Conv2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Conv2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=\"adadelta\",\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22046 samples, validate on 2756 samples\n",
      "Epoch 1/30\n",
      "22046/22046 [==============================] - 200s 9ms/step - loss: 0.4691 - acc: 0.7645 - val_loss: 0.1471 - val_acc: 0.9554\n",
      "Epoch 2/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1699 - acc: 0.9476 - val_loss: 0.1380 - val_acc: 0.9608\n",
      "Epoch 3/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1556 - acc: 0.9507 - val_loss: 0.1231 - val_acc: 0.9634\n",
      "Epoch 4/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1469 - acc: 0.9544 - val_loss: 0.1675 - val_acc: 0.9405\n",
      "Epoch 5/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1339 - acc: 0.9590 - val_loss: 0.1149 - val_acc: 0.9663\n",
      "Epoch 6/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1294 - acc: 0.9576 - val_loss: 0.1129 - val_acc: 0.9648\n",
      "Epoch 7/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1237 - acc: 0.9616 - val_loss: 0.1096 - val_acc: 0.9648\n",
      "Epoch 8/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1148 - acc: 0.9622 - val_loss: 0.1168 - val_acc: 0.9652\n",
      "Epoch 9/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1088 - acc: 0.9658 - val_loss: 0.1209 - val_acc: 0.9619\n",
      "Epoch 10/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.1026 - acc: 0.9667 - val_loss: 0.1126 - val_acc: 0.9630\n",
      "Epoch 11/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0933 - acc: 0.9686 - val_loss: 0.1128 - val_acc: 0.9652\n",
      "Epoch 12/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0921 - acc: 0.9696 - val_loss: 0.1313 - val_acc: 0.9666\n",
      "Epoch 13/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0842 - acc: 0.9731 - val_loss: 0.1144 - val_acc: 0.9688\n",
      "Epoch 14/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0734 - acc: 0.9757 - val_loss: 0.1402 - val_acc: 0.9637\n",
      "Epoch 15/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0671 - acc: 0.9785 - val_loss: 0.1339 - val_acc: 0.9612\n",
      "Epoch 16/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0589 - acc: 0.9808 - val_loss: 0.1819 - val_acc: 0.9550\n",
      "Epoch 17/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0475 - acc: 0.9857 - val_loss: 0.1622 - val_acc: 0.9634\n",
      "Epoch 18/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0504 - acc: 0.9845 - val_loss: 0.1447 - val_acc: 0.9655\n",
      "Epoch 19/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0436 - acc: 0.9857 - val_loss: 0.1729 - val_acc: 0.9619\n",
      "Epoch 20/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0363 - acc: 0.9896 - val_loss: 0.2458 - val_acc: 0.9601\n",
      "Epoch 21/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0368 - acc: 0.9884 - val_loss: 0.1908 - val_acc: 0.9601\n",
      "Epoch 22/30\n",
      "22046/22046 [==============================] - 192s 9ms/step - loss: 0.0333 - acc: 0.9907 - val_loss: 0.2602 - val_acc: 0.9601\n",
      "Epoch 23/30\n",
      "22046/22046 [==============================] - 191s 9ms/step - loss: 0.0299 - acc: 0.9917 - val_loss: 0.2921 - val_acc: 0.9608\n",
      "Epoch 24/30\n",
      "22046/22046 [==============================] - 191s 9ms/step - loss: 0.0304 - acc: 0.9916 - val_loss: 0.2820 - val_acc: 0.9630\n",
      "Epoch 25/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0275 - acc: 0.9925 - val_loss: 0.2376 - val_acc: 0.9597\n",
      "Epoch 26/30\n",
      "22046/22046 [==============================] - 191s 9ms/step - loss: 0.0227 - acc: 0.9938 - val_loss: 0.2777 - val_acc: 0.9619\n",
      "Epoch 27/30\n",
      "22046/22046 [==============================] - 191s 9ms/step - loss: 0.0247 - acc: 0.9941 - val_loss: 0.2404 - val_acc: 0.9670\n",
      "Epoch 28/30\n",
      "22046/22046 [==============================] - 190s 9ms/step - loss: 0.0238 - acc: 0.9946 - val_loss: 0.3309 - val_acc: 0.9550\n",
      "Epoch 29/30\n",
      "22046/22046 [==============================] - 191s 9ms/step - loss: 0.0275 - acc: 0.9941 - val_loss: 0.2738 - val_acc: 0.9608\n",
      "Epoch 30/30\n",
      "22046/22046 [==============================] - 189s 9ms/step - loss: 0.0217 - acc: 0.9950 - val_loss: 0.3123 - val_acc: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c9351f898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data = (x_val,y_val), epochs=EPOCHS, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2756/2756 [==============================] - 8s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4063726602521581, 0.9539187227866474]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard augment \n",
    "seq1 = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), \n",
    "    iaa.Fliplr(0.5), \n",
    "    iaa.GaussianBlur(sigma=(0, 3.0))\n",
    "])\n",
    "\n",
    "# new augment\n",
    "seq2 = iaa.Sequential([\n",
    "    iaa.ContrastNormalization((0.5, 1.5)),\n",
    "    iaa.Sometimes(0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    iaa.Sometimes(0.7, \n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        rotate=(-25, 25),\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        shear=(-25, 25)\n",
    "    ),\n",
    "    \n",
    "    #iaa.Sometimes(0.8, \n",
    "     #   iaa.CoarseDropout(0.03, size_percent=0.1)\n",
    "    #),\n",
    "], random_order=True) # apply augmenters in random order\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "def augment_data_minimal(x_values, y_values):\n",
    "    counter = 0\n",
    "    RESIZE_DIM = 96\n",
    "    X_values_augmented = []\n",
    "    Y_values_augmented = []\n",
    "    for x in x_values:\n",
    "        for p in range(2):\n",
    "            \n",
    "            # seq 1\n",
    "            Y_values_augmented.append( y_values[counter] )\n",
    "            images_aug = seq_standard.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
    "            X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
    "            \n",
    "            # seq 2\n",
    "            Y_values_augmented.append( y_values[counter] )\n",
    "            images_aug = seq_custom.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
    "            X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
    "\n",
    "        counter = counter + 1\n",
    "    \n",
    "    \n",
    "    # prev number of images = n\n",
    "    # augmented number of images = n * 4 ( 2 seq 2 times)\n",
    "    X_values_augmented = np.asarray( X_values_augmented )\n",
    "    Y_values_augmented = np.asarray( Y_values_augmented )\n",
    "    return (X_values_augmented, Y_values_augmented)\n",
    "  \n",
    "  \n",
    "  # test time augmentation\n",
    "def test_of_time(x_test):\n",
    "  '''\n",
    "  Arg: x_test: number of test samples of shape (N, w,h,3)\n",
    "  Returns the predicted labels using test time augmentation    \n",
    "  '''\n",
    " \n",
    "  pred_label = []\n",
    "  label = []\n",
    "  # number of samples in test set\n",
    "  l = len(x_test)\n",
    "  for i in range(l):\n",
    "      # normal sample\n",
    "      img = x_test[i]\n",
    "      # augmented sample reshaped(seq acceptd rank-4 tensor) and fed to sequences\n",
    "      img_a = seq1.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
    "      img_b = seq2.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
    "      #img_c = seq3.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\n",
    "\n",
    "      # augmented sample reshaped back in normal(rank-3 tensor)\n",
    "      img_a_out = img_a.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
    "      img_b_out = img_b.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
    "      #img_c_out = img_c.reshape(RESIZE_DIM,RESIZE_DIM,3)\n",
    "\n",
    "      # test of time!\n",
    "      y_test1 = model.predict(img_a_out[None,:,:,:])\n",
    "      y_test2 = model.predict(img_b_out[None,:,:,:])\n",
    "      #y_test3 = model.predict(img_c_out[None,:,:,:])\n",
    "      y_test3 = model.predict(img[None,:,:,:])\n",
    "\n",
    "      # change the params in the weighted average equation for minor changes in the performance\n",
    "      # future works: arithmetic mean\n",
    "\n",
    "      # coefficients should add up to 1!\n",
    "      #y_test = .2*y_test1 + .2*y_test2 + .2*y_test3 + .4*y_test4\n",
    "      y_test = .2*y_test1 + .2*y_test2 + .6*y_test3\n",
    "      label.append(y_test)\n",
    "\n",
    "  # convert to final predicted labels\n",
    "  pred_labels=np.concatenate(label)\n",
    "  return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 120000 into shape (1,96,96,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fd463c449be8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_of_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-9a33a309ae81>\u001b[0m in \u001b[0;36mtest_of_time\u001b[1;34m(x_test)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[1;31m# augmented sample reshaped(seq acceptd rank-4 tensor) and fed to sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       \u001b[0mimg_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRESIZE_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRESIZE_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m       \u001b[0mimg_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRESIZE_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRESIZE_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m       \u001b[1;31m#img_c = seq3.augment_images(img.reshape(1,RESIZE_DIM,RESIZE_DIM,3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 120000 into shape (1,96,96,3)"
     ]
    }
   ],
   "source": [
    "label_pred = test_of_time(x_test)\n",
    "labels= np.array([np.argmax(pred) for pred in label_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2756,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TTA:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aiman\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy with TTA: ',np.mean((y_test==labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
