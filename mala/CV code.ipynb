{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Change n_splits = 5 for 5 fold CV\n",
    "##Sklearn StratifiedKFold doesn't work for one hot encoding hence binarized it\n",
    "## so dense layer = 1 and activation = sigmoid here\n",
    "## If you don't want to do it, just use model.fit(val_split = 0.2) and run 5 different models and take their test score average\n",
    "## for any case don't split dataset into training/test/val you only need training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_train = y_train[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.8105 - acc: 0.6902\n",
      "Epoch 2/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.2246 - acc: 0.9198\n",
      "Epoch 3/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1709 - acc: 0.9420\n",
      "Epoch 4/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.1522 - acc: 0.9495\n",
      "Epoch 5/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.1415 - acc: 0.9522\n",
      "Epoch 6/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.1241 - acc: 0.9564\n",
      "Epoch 7/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1193 - acc: 0.9595\n",
      "Epoch 8/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1064 - acc: 0.9643\n",
      "Epoch 9/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1040 - acc: 0.9638\n",
      "Epoch 10/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0866 - acc: 0.9690\n",
      "Epoch 11/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0878 - acc: 0.9683\n",
      "Epoch 12/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0805 - acc: 0.9721\n",
      "Epoch 13/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0659 - acc: 0.9772\n",
      "Epoch 14/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0580 - acc: 0.9797\n",
      "Epoch 15/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.0545 - acc: 0.9807\n",
      "Epoch 16/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.0472 - acc: 0.9829\n",
      "Epoch 17/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.0407 - acc: 0.9851\n",
      "Epoch 18/20\n",
      "11023/11023 [==============================] - 94s 9ms/step - loss: 0.0415 - acc: 0.9848\n",
      "Epoch 19/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.0386 - acc: 0.9857\n",
      "Epoch 20/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.0284 - acc: 0.9900\n",
      "Epoch 1/20\n",
      "11023/11023 [==============================] - 97s 9ms/step - loss: 0.8571 - acc: 0.6150\n",
      "Epoch 2/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.3003 - acc: 0.8803\n",
      "Epoch 3/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.1882 - acc: 0.9388\n",
      "Epoch 4/20\n",
      "11023/11023 [==============================] - 94s 9ms/step - loss: 0.1628 - acc: 0.9470\n",
      "Epoch 5/20\n",
      "11023/11023 [==============================] - 93s 8ms/step - loss: 0.1422 - acc: 0.9519\n",
      "Epoch 6/20\n",
      "11023/11023 [==============================] - 95s 9ms/step - loss: 0.1339 - acc: 0.9538\n",
      "Epoch 7/20\n",
      "11023/11023 [==============================] - 94s 9ms/step - loss: 0.1185 - acc: 0.9605\n",
      "Epoch 8/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1092 - acc: 0.9633\n",
      "Epoch 9/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.1036 - acc: 0.9634\n",
      "Epoch 10/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0891 - acc: 0.9681\n",
      "Epoch 11/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0774 - acc: 0.9720\n",
      "Epoch 12/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0726 - acc: 0.9743\n",
      "Epoch 13/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0633 - acc: 0.9769\n",
      "Epoch 14/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0585 - acc: 0.9799\n",
      "Epoch 15/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0515 - acc: 0.9820\n",
      "Epoch 16/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0399 - acc: 0.9859\n",
      "Epoch 17/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.0318 - acc: 0.9894\n",
      "Epoch 18/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.0266 - acc: 0.9907\n",
      "Epoch 19/20\n",
      "11023/11023 [==============================] - 91s 8ms/step - loss: 0.0280 - acc: 0.9901\n",
      "Epoch 20/20\n",
      "11023/11023 [==============================] - 92s 8ms/step - loss: 0.0291 - acc: 0.9898\n",
      "Total CV score is 0.9485620974380482\n",
      "Total CV score std is 0.00408237322503896\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "cvscores = []\n",
    "IMAGE_SIZE = 200\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    opt = SGD(lr=0.01)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = opt,  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=x_train[train], y=y_train[train], batch_size = BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
    "    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "    cvscores.append(scores[1])\n",
    "print('Total CV score is {}'.format(np.mean(cvscores)))\n",
    "print('Total CV score std is {}'.format(np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
